{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7cfb056c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 4980, Val: 1246\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('final_binarized_dataset.csv')\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df.to_csv('train.csv', index=False)\n",
    "val_df.to_csv('val.csv', index=False)\n",
    "print(f'Train: {len(train_df)}, Val: {len(val_df)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33dcc39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manishank/miniconda3/envs/cvlab/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/manishank/miniconda3/envs/cvlab/lib/python3.10/site-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "/var/folders/vd/jrk7j1cs34nfvmbwrpr_gnn00000gn/T/ipykernel_3699/1663174678.py:67: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "class RoadSegmentationDataset(Dataset):\n",
    "    def __init__(self, csv_file, transforms=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def preprocess_image(self, image):\n",
    "        # 1. Denoising\n",
    "        image = cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 21)\n",
    "        \n",
    "        # 2. Histogram Equalization (CLAHE) for better contrast\n",
    "        lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "        lab[:, :, 0] = clahe.apply(lab[:, :, 0])\n",
    "        image = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
    "        \n",
    "        # 3. Sharpening to enhance road edges\n",
    "        kernel = np.array([[-1,-1,-1],\n",
    "                          [-1, 9,-1],\n",
    "                          [-1,-1,-1]])\n",
    "        image = cv2.filter2D(image, -1, kernel)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx]['image_path']\n",
    "        mask_path = self.data.iloc[idx]['mask_path']\n",
    "        \n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Apply advanced preprocessing\n",
    "        image = self.preprocess_image(image)\n",
    "        \n",
    "        mask = cv2.imread(mask_path, 0)\n",
    "        \n",
    "        if self.transforms:\n",
    "            augmented = self.transforms(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "        \n",
    "        image = image.float() / 255.0\n",
    "        mask = mask.float() / 255.0\n",
    "        mask = mask.unsqueeze(0)\n",
    "        \n",
    "        return image, mask\n",
    "\n",
    "# More aggressive augmentations\n",
    "train_transforms = A.Compose([\n",
    "    A.Resize(512, 512),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=45, p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n",
    "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.3),\n",
    "    A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
    "    A.GaussianBlur(blur_limit=(3, 7), p=0.2),\n",
    "    A.ElasticTransform(alpha=120, sigma=120 * 0.05, p=0.2),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transforms = A.Compose([\n",
    "    A.Resize(512, 512),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "train_dataset = RoadSegmentationDataset('train.csv', transforms=train_transforms)\n",
    "val_dataset = RoadSegmentationDataset('val.csv', transforms=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f3683a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Metal) device\n",
      "DeepLabv3+ with ResNet50 loaded\n"
     ]
    }
   ],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "\n",
    "model = smp.DeepLabV3Plus(\n",
    "    encoder_name=\"resnet50\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=3,\n",
    "    classes=1,\n",
    "    activation=None\n",
    ")\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Using MPS (Metal) device\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = model.to(device)\n",
    "print('DeepLabv3+ with ResNet50 loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3543ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING STARTED - DeepLabv3+ ResNet50 | 512x512 | LR=1e-3 | Batch=4\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/40 [Train]:   0%|          | 0/1245 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 70\u001b[0m\n\u001b[1;32m     68\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m     69\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, masks)\n\u001b[0;32m---> 70\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     73\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/cvlab/lib/python3.10/site-packages/torch/_tensor.py:647\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    639\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    640\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    645\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    646\u001b[0m     )\n\u001b[0;32m--> 647\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cvlab/lib/python3.10/site-packages/torch/autograd/__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cvlab/lib/python3.10/site-packages/torch/autograd/graph.py:829\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        smooth = 1e-5\n",
    "        pred = torch.sigmoid(pred)\n",
    "        intersection = (pred * target).sum(dim=(2, 3))\n",
    "        union = pred.sum(dim=(2, 3)) + target.sum(dim=(2, 3))\n",
    "        dice = (2.0 * intersection + smooth) / (union + smooth)\n",
    "        return 1 - dice.mean()\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "        self.dice = DiceLoss()\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        return self.bce(pred, target) + self.dice(pred, target)\n",
    "\n",
    "def calculate_dice(pred, target):\n",
    "    smooth = 1e-5\n",
    "    pred = torch.sigmoid(pred) > 0.5\n",
    "    target = target > 0.5\n",
    "    intersection = (pred & target).float().sum((1, 2, 3))\n",
    "    union = pred.sum((1, 2, 3)) + target.sum((1, 2, 3))\n",
    "    dice = (2.0 * intersection + smooth) / (union + smooth)\n",
    "    return dice.mean().item()\n",
    "\n",
    "def calculate_iou(pred, target):\n",
    "    pred = torch.sigmoid(pred) > 0.5\n",
    "    target = target > 0.5\n",
    "    intersection = (pred & target).float().sum((1, 2, 3))\n",
    "    union = (pred | target).float().sum((1, 2, 3))\n",
    "    iou = (intersection + 1e-5) / (union + 1e-5)\n",
    "    return iou.mean().item()\n",
    "\n",
    "criterion = CombinedLoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)\n",
    "\n",
    "num_epochs = 40\n",
    "best_val_iou = 0.0\n",
    "best_val_dice = 0.0\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING STARTED - DeepLabv3+ ResNet50 | 512x512 | LR=1e-3 | Batch=4\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_iou = 0.0\n",
    "    train_dice = 0.0\n",
    "    \n",
    "    train_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
    "    for images, masks in train_bar:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_iou += calculate_iou(outputs, masks)\n",
    "        train_dice += calculate_dice(outputs, masks)\n",
    "        train_bar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    train_iou /= len(train_loader)\n",
    "    train_dice /= len(train_loader)\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_iou = 0.0\n",
    "    val_dice = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Val]  ')\n",
    "        for images, masks in val_bar:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_iou += calculate_iou(outputs, masks)\n",
    "            val_dice += calculate_dice(outputs, masks)\n",
    "            val_bar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_iou /= len(val_loader)\n",
    "    val_dice /= len(val_loader)\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(f\"EPOCH {epoch+1}/{num_epochs} RESULTS:\")\n",
    "    print(\"-\"*80)\n",
    "    print(f\"  TRAIN | Loss: {train_loss:.4f} | IoU: {train_iou:.4f} ({train_iou*100:.2f}%) | Dice: {train_dice:.4f} ({train_dice*100:.2f}%)\")\n",
    "    print(f\"  VAL   | Loss: {val_loss:.4f} | IoU: {val_iou:.4f} ({val_iou*100:.2f}%) | Dice: {val_dice:.4f} ({val_dice*100:.2f}%)\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"  Learning Rate: {current_lr}\")\n",
    "    scheduler.step(val_iou)\n",
    "    new_lr = optimizer.param_groups[0]['lr']\n",
    "    if new_lr < current_lr:\n",
    "        print(f\"  → Learning rate reduced to {new_lr}\")\n",
    "    \n",
    "    if val_iou > best_val_iou:\n",
    "        best_val_iou = val_iou\n",
    "        best_val_dice = val_dice\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f\"  ✓ NEW BEST MODEL SAVED! Val IoU: {val_iou:.4f} ({val_iou*100:.2f}%) | Val Dice: {val_dice:.4f} ({val_dice*100:.2f}%)\")\n",
    "    print(\"-\"*80)\n",
    "    print()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"  Best Validation IoU:  {best_val_iou:.4f} ({best_val_iou*100:.2f}%)\")\n",
    "print(f\"  Best Validation Dice: {best_val_dice:.4f} ({best_val_dice*100:.2f}%)\")\n",
    "print(\"=\"*80 + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
